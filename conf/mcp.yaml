defaults:
    - base
    - override finetune: grpo
    - _self_

llm:
  parameters:
    max_tokens: 8192

test_llm:
  parameters:
    max_tokens: 8192

actor:
  rollout_policy: pipelinerl.domains.mcp.generate_mcp_rollout
  system_prompt: Please reason step by step, and put your final answer within \boxed{{}}.
  llm_max_rollouts: 64
  task_template: |-
    {task}
  shared_memory_entry_size: 10000000

finetune:
  seq_length: 128000
  seq_parallel: 8

dataset_loader: pipelinerl.domains.math.load_datasets
train_dataset_names:
- open_reasoner_zero_57k
- open_reasoner_zero_extended_72k 
test_dataset_names:
  - aime_2025

vllm_config:
  use_v1: false
  vllm_kwargs:
    enable-auto-tool-choice: ""
    tool-call-parser: rl_tool
    tool-parser-plugin: ${hydra:runtime.cwd}/pipelinerl/rl_tool_parser_plugin.py
    max-num-seqs: ${actor.llm_max_rollouts}
    max-num-batched-tokens: 4096
    max_model_len: 128000
    gpu-memory-utilization: 0.85

environment:
  _target_: pipelinerl.domains.mcp.env_server.EmbeddedMCPEnvironment
  config_path: ${hydra:runtime.cwd}/conf/mcp/python.json
  tools_whitelist:
    - run_python_code
  read_timeout_seconds: 600
  use_cache: false
  runtime_pool_workers: 4
  offload_tools:
    - run_python_code


world:
  env_replicas_per_actor: 8
  environment_mode: embedded

agent_max_loops: 3
agent:
  _target_: tapeagents.agent.Agent
  name : mcp_agent
  max_iterations: 3
  store_llm_calls: true
  templates:
    system_prompt: |
      You are a math-focused AI Agent. Solve problems by combining clear symbolic reasoning
      with short, deterministic Python code.
      Keep your replies concise and direct. Prioritize clarity and avoid over-elaboration.
      Always present the final answer in LaTeX \boxed{{}}.
      Do not express emotions or opinions about user questions.

      Workflow:
      1. Draft a brief plan in plain text.
      2. Execute one run_python_code call to compute or verify the result.
      3. Finalize by calling MathAnswer with the LaTeX-formatted answer.

      Python execution policy (run_python_code):
      - Use Python strictly for pure computation to verify and validate the final answer.
      - No network, file system, OS or environment access.
      - Keep snippets minimal and self-contained; avoid large outputs and long-running loops; print only the final result.

      Validation:
      - Cross-check results (alternative derivation, invariants, higher precision) before finalizing.
      - If execution fails, propose the minimal fix and retry.
      Keep replies direct and avoid unnecessary text.
    allowed_tools: |
      You can call the following tools:
      {tools_description}
      - run_python_code: deterministic math code; print only the final value.
      - MathAnswer: return the LaTeX \boxed{{}} answer when the solution is verified.
      Always verify with run_python_code before invoking MathAnswer.
    thought_format: |
      Important! Respond with the plain text, do not include any JSON or code.
      Do not output anything besides what I asked in this message.
    allowed_steps: |
      Workflow summary:
      - Plan briefly in plain text.
      - Call run_python_code exactly once per loop to compute/verify.
      - Finish with a single MathAnswer tool call carrying the \boxed{{}} result.
    format: |
      For finalization, reply with a single short sentence that ends in the \boxed{{}} answer,
      immediately followed by the MathAnswer function call containing the same \boxed{{}} value.
      Never emit unrelated JSON wrappers or duplicate the final thought.
      

  nodes:
    - _target_: tapeagents.nodes.StandardNode
      name: plan
      system_prompt: ${agent.templates.system_prompt}
      guidance: |
        Produce a concise math plan (formulas/checks). You will ALWAYS verify by executing Python code.
        ${agent.templates.thought_format}
      steps_prompt: ${agent.templates.allowed_tools}
      trim_obs_except_last_n: 2

    - _target_: tapeagents.nodes.StandardNode
      name: code
      system_prompt: ${agent.templates.system_prompt}
      guidance: |
        ALWAYS call run_python_code once to compute/verify the result.
        Use exact, deterministic code; print only the final scalar or tuple.
        If code fails, fix minimally and call run_python_code again after reviewing the error.
      use_known_actions: true
      use_function_calls: true
      trim_obs_except_last_n: 2

    - _target_: tapeagents.nodes.StandardNode
      name: finalize
      system_prompt: ${agent.templates.system_prompt}
      guidance: |
        Read the last Python stdout value. First, state the answer in one short sentence that ends with LaTeX \boxed{{}}.
        Immediately after that sentence, call the MathAnswer tool exactly once with:
          name: MathAnswer
          arguments: {"answer": "<final answer in LaTeX \\boxed{}>"}
        Do not add any extra text around the tool call. Once the sentence is emitted, return only the MathAnswer function call.
      steps:
        - pipelinerl.domains.mcp.steps.MathAnswer
      use_known_actions: true
      use_function_calls: true
      trim_obs_except_last_n: 2
      next_node: code

# model_path: Qwen/Qwen3-8B
model_path: /mnt/llmd/base_models/ServiceNow-AI/7_9_25_14b_text_reasoning_sft

# Local reward shaping for tool usage
python_tool_shaping:
  bonus_on_correct_with_python: 0.2
  penalty_on_incorrect_without_python: 0.1
  max_abs: 0.2

# Encourage concise outputs (penalize long completions)
length_shaping:
  target_ratio: 0.1                # 10% of max_tokens; auto scales with max_tokens
  min_target_tokens: 256           # lower clamp
  max_target_tokens: 2048          # upper clamp
  slope: 0.001                     # penalty per token beyond target
  max_penalty: 0.2                 # clamp absolute penalty
  bonus_on_short_correct: 0.05     # bonus if correct and concise
